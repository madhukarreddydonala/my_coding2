{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8edbd174-bed9-446e-a00c-f3020c20b7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\madhu\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from python-docx) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12031b14-ad91-4371-b5ce-66b95eb96e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f58d68-067f-4e2a-9b85-9feaed0abcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=open(\"2211CS020136  ML Alpha.docx\",\"rb\")\n",
    "document=docx.Document(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df5852ad-e3b2-4bcf-a07b-9f69be155ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MACHINE LEARNING ASSN-6Course code: MR22-1CS0204Submitted To: Professor.A.SHIVA KUMARDepartment of Artificial intelligence and Machine Learning Malla Reddy UniversitySubmitted By:      D.MADHUKAR2211CS020136AIML-ALPHADate Of Submission:14-03-2024Primary Objectives of unsupervised learning specially focusing on clustering algorithms?A:Unsupervised learning Unsupervised learning is a type of machine learning where the algorithm is given data without explicit instructions on what to do with it. The system tries to learn the patterns and relationships within the data on its own. There are two main types of unsupervised learning: clustering and dimensionality reduction. 1. Clustering:  K-Means Clustering: This algorithm partitions data into 'k' clusters based on similarity. For example, in customer segmentation, you can use K-means to group customers with similar purchasing behavior.  Hierarchical Clustering: It creates a tree of clusters, where the root is a single cluster containing all data points, and the leaves are individual data points. This can be used in taxonomy or gene expression analysis. 2. Dimensionality Reduction:  Principal Component Analysis (PCA): PCA is used to reduce the number of features in a dataset while retaining its essential information. It's often applied in image compression or feature extraction for machine learning models.  t-Distributed Stochastic Neighbor Embedding (t-SNE): t-SNE is used for visualizing high-dimensional data in two or three dimensions. It's useful for exploring the structure of data and finding patterns. For instance, visualizing similarities between words in natural language processing. 3. Association Rule Learning:  Apriori Algorithm: This algorithm is used to discover associations between different items in a dataset. For example, in retail, it can identify relationships like \"Customers who buy product A are likely to buy product B.\" 4. Generative Models:  Generative Adversarial Networks (GANs): GANs consist of a generator and a discriminator that are trained together. GANs can generate new data instances that resemble the training data. They are used in image and video generation tasks. 5. Autoencoders:  Variational Autoencoders (VAE): VAEs are a type of autoencoder that learns a probabilistic mapping between the data space and a latent space. They are used for generating new data points and can be applied to image and text generation. Unsupervised learning is particularly valuable when you have a large amount of unlabeled data and want to explore the underlying structure or relationships within it. It is widely used in various domains, including pattern recognition, anomaly detection, and feature learning. Clustering algorithms Clustering algorithms in unsupervised learning aim to group similar data points together into clusters or segments based on certain criteria. The goal is to discover hidden patterns or structures within the data. There are various clustering algorithms, each with its own approach and characteristics. Here are a few commonly used clustering algorithms: 1. K-Means Clustering:  Objective: Partition the data into 'k' clusters based on similarity.  Process: It starts by randomly selecting 'k' centroids (cluster centers) and assigns each data point to the nearest centroid. Then, it recalculates the centroids based on the mean of the data points in each cluster. This process iterates until convergence.  Example: Customer segmentation in marketing based on purchasing behavior. 2. Hierarchical Clustering:  Objective: Create a tree-like structure (dendrogram) of clusters.  Process: It begins with each data point as a separate cluster and merges the closest clusters iteratively until all points belong to a single cluster. The resulting dendrogram can be cut at different levels to obtain clusters of varying sizes.  Example: Taxonomy in biology or organizational hierarchy. 3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise):  Objective: Identify clusters based on the density of data points.  Process: It defines clusters as dense regions separated by areas of lower point density. It classifies points as core points, border points, or outliers (noise) based on their density and proximity to other points.  Example: Anomaly detection in network traffic where unusual patterns represent potential security threats. 4. Mean Shift:  Objective: Discover modes or peaks of high-density regions.  Process: It iteratively shifts the center of a kernel until it converges to a highdensity region. The algorithm is adaptive and does not require specifying the number of clusters beforehand.  Example: Image segmentation where pixels with similar colors form clusters. 2 5. Agglomerative Clustering:  Objective: Build clusters by successively merging or agglomerating data points.  Process: It starts with each data point as a singleton cluster and merges the closest pairs iteratively until a stopping criterion is met. The result is a dendrogram that can be cut to form clusters.  Example: Social network analysis to identify communities within a network. 6. Gaussian Mixture Model (GMM):  Objective: Model the data as a mixture of several Gaussian distributions.  Process: It assumes that the data is generated by a mixture of several Gaussian distributions. The algorithm estimates the parameters of these distributions, including means and covariances, to identify clusters.  Example: Speech and handwriting recognition where multiple patterns contribute to the observed data. Explain K-Means Algorithm with Sample Data Set?A:K-Means algorithm The K-Means algorithm is a popular unsupervised machine learning algorithm used for clustering data. The goal of K-Means is to partition a dataset into 'k' clusters, where each data point belongs to the cluster with the nearest mean. Here's a detailed explanation of the K-Means algorithm: Key Concepts:  Unsupervised Learning: It works with unlabeled data, finding patterns on its own.  Clustering: It groups similar data points together into distinct clusters.  Centroids: Each cluster has a central point (centroid), representing the \"average\" of data points within it.  Distance Metric: It measures how close data points are to each other, usually using Euclidean distance. Algorithm Steps: Step 1: Initialization  Input: Dataset with 'n' data points and the desired number of clusters 'k'.  Process:  Randomly select 'k' data points from the dataset as initial centroids. Step 2: Assignment  Input: Initial centroids.  Process:  For each data point in the dataset, calculate the Euclidean distance to each centroid.  Assign the data point to the cluster associated with the nearest centroid. 3 Step 3: Update  Input: Assigned clusters.  Process:  Recalculate the centroids of each cluster by computing the mean of all data points in that cluster. Step 4: Convergence Check  Input: Updated centroids.  Process:  Repeat the assignment and update steps iteratively until convergence.  Convergence occurs when the centroids no longer change significantly or after a fixed number of iterations. Step 5: Result  Output: Final clusters.  Process:  Once convergence is reached, the algorithm stops, and each data point is assigned to a specific cluster. Pseudo code: 1. Randomly initialize k centroids: c_1, c_2, ..., c_k 2. Repeat until convergence: a. For each data point x_i, assign it to the cluster with the closest centroid: j = argmin_k ||x_i - c_k||^2 b. Update centroids: c_k = (1/|cluster k|) * Σ x_i for all i in cluster kProgram 1: Implement a program to cluster a dataset using K-means clustering. Example 1: iris flowers OUTPUT:\n"
     ]
    }
   ],
   "source": [
    "docu=\"\"\n",
    "for para in document.paragraphs:\n",
    "    docu+=para.text\n",
    "print(docu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a24ed3a6-85e0-4ce4-84c3-6f24012bb40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content of paragraphs0 is:     \n",
      "\n",
      "The content of paragraphs1 is: \n",
      "\n",
      "The content of paragraphs2 is: \n",
      "\n",
      "The content of paragraphs3 is: \n",
      "\n",
      "The content of paragraphs4 is: MACHINE LEARNING ASSN-6\n",
      "\n",
      "The content of paragraphs5 is: Course code: MR22-1CS0204\n",
      "\n",
      "The content of paragraphs6 is: \n",
      "\n",
      "The content of paragraphs7 is: \n",
      "\n",
      "The content of paragraphs8 is: Submitted To: \n",
      "\n",
      "The content of paragraphs9 is: Professor.A.SHIVA KUMAR\n",
      "\n",
      "The content of paragraphs10 is: Department of Artificial intelligence and Machine Learning Malla Reddy University\n",
      "\n",
      "The content of paragraphs11 is: \n",
      "\n",
      "The content of paragraphs12 is: \n",
      "\n",
      "The content of paragraphs13 is: Submitted By: \n",
      "\n",
      "The content of paragraphs14 is:      D.MADHUKAR\n",
      "\n",
      "The content of paragraphs15 is: 2211CS020136\n",
      "\n",
      "The content of paragraphs16 is: AIML-ALPHA\n",
      "\n",
      "The content of paragraphs17 is: \n",
      "\n",
      "The content of paragraphs18 is: \n",
      "\n",
      "The content of paragraphs19 is: Date Of Submission:14-03-2024\n",
      "\n",
      "The content of paragraphs20 is: Primary Objectives of unsupervised learning specially focusing on clustering algorithms?\n",
      "\n",
      "The content of paragraphs21 is: A:\n",
      "\n",
      "The content of paragraphs22 is: Unsupervised learning \n",
      "\n",
      "The content of paragraphs23 is: Unsupervised learning is a type of machine learning where the algorithm is given data without \n",
      "\n",
      "The content of paragraphs24 is: explicit instructions on what to do with it. The system tries to learn the patterns and relationships \n",
      "\n",
      "The content of paragraphs25 is: within the data on its own. There are two main types of unsupervised learning: clustering and \n",
      "\n",
      "The content of paragraphs26 is: dimensionality reduction. \n",
      "\n",
      "The content of paragraphs27 is: 1. Clustering: \n",
      "\n",
      "The content of paragraphs28 is:  K-Means Clustering: This algorithm partitions data into 'k' clusters based on \n",
      "\n",
      "The content of paragraphs29 is: similarity. For example, in customer segmentation, you can use K-means to group \n",
      "\n",
      "The content of paragraphs30 is: customers with similar purchasing behavior. \n",
      "\n",
      "The content of paragraphs31 is:  Hierarchical Clustering: It creates a tree of clusters, where the root is a single \n",
      "\n",
      "The content of paragraphs32 is: cluster containing all data points, and the leaves are individual data points. This \n",
      "\n",
      "The content of paragraphs33 is: can be used in taxonomy or gene expression analysis. \n",
      "\n",
      "The content of paragraphs34 is: 2. Dimensionality Reduction: \n",
      "\n",
      "The content of paragraphs35 is:  Principal Component Analysis (PCA): PCA is used to reduce the number of \n",
      "\n",
      "The content of paragraphs36 is: features in a dataset while retaining its essential information. It's often applied in \n",
      "\n",
      "The content of paragraphs37 is: image compression or feature extraction for machine learning models. \n",
      "\n",
      "The content of paragraphs38 is:  t-Distributed Stochastic Neighbor Embedding (t-SNE): t-SNE is used for \n",
      "\n",
      "The content of paragraphs39 is: visualizing high-dimensional data in two or three dimensions. It's useful for \n",
      "\n",
      "The content of paragraphs40 is: exploring the structure of data and finding patterns. For instance, visualizing \n",
      "\n",
      "The content of paragraphs41 is: similarities between words in natural language processing. \n",
      "\n",
      "The content of paragraphs42 is: 3. Association Rule Learning: \n",
      "\n",
      "The content of paragraphs43 is:  Apriori Algorithm: This algorithm is used to discover associations between \n",
      "\n",
      "The content of paragraphs44 is: different items in a dataset. For example, in retail, it can identify relationships like \n",
      "\n",
      "The content of paragraphs45 is: \"Customers who buy product A are likely to buy product B.\" \n",
      "\n",
      "The content of paragraphs46 is: 4. Generative Models: \n",
      "\n",
      "The content of paragraphs47 is:  Generative Adversarial Networks (GANs): GANs consist of a generator and a \n",
      "\n",
      "The content of paragraphs48 is: discriminator that are trained together. GANs can generate new data instances that \n",
      "\n",
      "The content of paragraphs49 is: resemble the training data. They are used in image and video generation tasks. \n",
      "\n",
      "The content of paragraphs50 is: \n",
      "\n",
      "The content of paragraphs51 is: \n",
      "\n",
      "The content of paragraphs52 is: \n",
      "\n",
      "The content of paragraphs53 is: \n",
      "\n",
      "The content of paragraphs54 is: 5. Autoencoders: \n",
      "\n",
      "The content of paragraphs55 is:  Variational Autoencoders (VAE): VAEs are a type of autoencoder that learns a \n",
      "\n",
      "The content of paragraphs56 is: probabilistic mapping between the data space and a latent space. They are used \n",
      "\n",
      "The content of paragraphs57 is: for generating new data points and can be applied to image and text generation. \n",
      "\n",
      "The content of paragraphs58 is: Unsupervised learning is particularly valuable when you have a large amount of unlabeled data \n",
      "\n",
      "The content of paragraphs59 is: and want to explore the underlying structure or relationships within it. It is widely used in \n",
      "\n",
      "The content of paragraphs60 is: various domains, including pattern recognition, anomaly detection, and feature learning. \n",
      "\n",
      "The content of paragraphs61 is: \n",
      "\n",
      "The content of paragraphs62 is: \n",
      "\n",
      "The content of paragraphs63 is: Clustering algorithms \n",
      "\n",
      "The content of paragraphs64 is: Clustering algorithms in unsupervised learning aim to group similar data points together into \n",
      "\n",
      "The content of paragraphs65 is: clusters or segments based on certain criteria. The goal is to discover hidden patterns or \n",
      "\n",
      "The content of paragraphs66 is: structures within the data. There are various clustering algorithms, each with its own approach \n",
      "\n",
      "The content of paragraphs67 is: and characteristics. Here are a few commonly used clustering algorithms: \n",
      "\n",
      "The content of paragraphs68 is: 1. K-Means Clustering: \n",
      "\n",
      "The content of paragraphs69 is:  Objective: Partition the data into 'k' clusters based on similarity. \n",
      "\n",
      "The content of paragraphs70 is:  Process: It starts by randomly selecting 'k' centroids (cluster centers) and assigns \n",
      "\n",
      "The content of paragraphs71 is: each data point to the nearest centroid. Then, it recalculates the centroids based on \n",
      "\n",
      "The content of paragraphs72 is: the mean of the data points in each cluster. This process iterates until \n",
      "\n",
      "The content of paragraphs73 is: convergence. \n",
      "\n",
      "The content of paragraphs74 is:  Example: Customer segmentation in marketing based on purchasing behavior. \n",
      "\n",
      "The content of paragraphs75 is: 2. Hierarchical Clustering: \n",
      "\n",
      "The content of paragraphs76 is:  Objective: Create a tree-like structure (dendrogram) of clusters. \n",
      "\n",
      "The content of paragraphs77 is:  Process: It begins with each data point as a separate cluster and merges the \n",
      "\n",
      "The content of paragraphs78 is: closest clusters iteratively until all points belong to a single cluster. The resulting \n",
      "\n",
      "The content of paragraphs79 is: dendrogram can be cut at different levels to obtain clusters of varying sizes. \n",
      "\n",
      "The content of paragraphs80 is:  Example: Taxonomy in biology or organizational hierarchy. \n",
      "\n",
      "The content of paragraphs81 is: 3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise): \n",
      "\n",
      "The content of paragraphs82 is:  Objective: Identify clusters based on the density of data points. \n",
      "\n",
      "The content of paragraphs83 is:  Process: It defines clusters as dense regions separated by areas of lower point \n",
      "\n",
      "The content of paragraphs84 is: density. It classifies points as core points, border points, or outliers (noise) based \n",
      "\n",
      "The content of paragraphs85 is: on their density and proximity to other points. \n",
      "\n",
      "The content of paragraphs86 is:  Example: Anomaly detection in network traffic where unusual patterns represent \n",
      "\n",
      "The content of paragraphs87 is: potential security threats. \n",
      "\n",
      "The content of paragraphs88 is: \n",
      "\n",
      "The content of paragraphs89 is: 4. Mean Shift: \n",
      "\n",
      "The content of paragraphs90 is:  Objective: Discover modes or peaks of high-density regions. \n",
      "\n",
      "The content of paragraphs91 is:  Process: It iteratively shifts the center of a kernel until it converges to a high\n",
      "\n",
      "The content of paragraphs92 is: density region. The algorithm is adaptive and does not require specifying the \n",
      "\n",
      "The content of paragraphs93 is: number of clusters beforehand. \n",
      "\n",
      "The content of paragraphs94 is:  Example: Image segmentation where pixels with similar colors form clusters. \n",
      "\n",
      "The content of paragraphs95 is: 2 5. Agglomerative Clustering: \n",
      "\n",
      "The content of paragraphs96 is:  Objective: Build clusters by successively merging or agglomerating data points. \n",
      "\n",
      "The content of paragraphs97 is:  Process: It starts with each data point as a singleton cluster and merges the closest \n",
      "\n",
      "The content of paragraphs98 is: pairs iteratively until a stopping criterion is met. The result is a dendrogram that \n",
      "\n",
      "The content of paragraphs99 is: can be cut to form clusters. \n",
      "\n",
      "The content of paragraphs100 is:  Example: Social network analysis to identify communities within a network. \n",
      "\n",
      "The content of paragraphs101 is: 6. Gaussian Mixture Model (GMM): \n",
      "\n",
      "The content of paragraphs102 is:  Objective: Model the data as a mixture of several Gaussian distributions. \n",
      "\n",
      "The content of paragraphs103 is:  Process: It assumes that the data is generated by a mixture of several Gaussian \n",
      "\n",
      "The content of paragraphs104 is: distributions. The algorithm estimates the parameters of these distributions, \n",
      "\n",
      "The content of paragraphs105 is: including means and covariances, to identify clusters. \n",
      "\n",
      "The content of paragraphs106 is:  Example: Speech and handwriting recognition where multiple patterns contribute \n",
      "\n",
      "The content of paragraphs107 is: to the observed data. \n",
      "\n",
      "The content of paragraphs108 is: \n",
      "\n",
      "The content of paragraphs109 is: \n",
      "\n",
      "The content of paragraphs110 is: \n",
      "\n",
      "The content of paragraphs111 is: \n",
      "\n",
      "The content of paragraphs112 is: \n",
      "\n",
      "The content of paragraphs113 is: \n",
      "\n",
      "The content of paragraphs114 is: \n",
      "\n",
      "The content of paragraphs115 is: \n",
      "\n",
      "The content of paragraphs116 is: \n",
      "\n",
      "The content of paragraphs117 is: \n",
      "\n",
      "The content of paragraphs118 is: \n",
      "\n",
      "The content of paragraphs119 is: \n",
      "\n",
      "The content of paragraphs120 is: \n",
      "\n",
      "The content of paragraphs121 is: \n",
      "\n",
      "The content of paragraphs122 is: \n",
      "\n",
      "The content of paragraphs123 is: \n",
      "\n",
      "The content of paragraphs124 is: \n",
      "\n",
      "The content of paragraphs125 is: \n",
      "\n",
      "The content of paragraphs126 is: \n",
      "\n",
      "The content of paragraphs127 is: Explain K-Means Algorithm with Sample Data Set?\n",
      "\n",
      "The content of paragraphs128 is: A:\n",
      "\n",
      "The content of paragraphs129 is: K-Means algorithm \n",
      "\n",
      "The content of paragraphs130 is: The K-Means algorithm is a popular unsupervised machine learning algorithm used for \n",
      "\n",
      "The content of paragraphs131 is: clustering data. The goal of K-Means is to partition a dataset into 'k' clusters, where each data \n",
      "\n",
      "The content of paragraphs132 is: point belongs to the cluster with the nearest mean. Here's a detailed explanation of the K-Means \n",
      "\n",
      "The content of paragraphs133 is: algorithm: \n",
      "\n",
      "The content of paragraphs134 is: Key Concepts: \n",
      "\n",
      "The content of paragraphs135 is:  Unsupervised Learning: It works with unlabeled data, finding patterns on its own. \n",
      "\n",
      "The content of paragraphs136 is:  Clustering: It groups similar data points together into distinct clusters. \n",
      "\n",
      "The content of paragraphs137 is:  Centroids: Each cluster has a central point (centroid), representing the \"average\" of data \n",
      "\n",
      "The content of paragraphs138 is: points within it. \n",
      "\n",
      "The content of paragraphs139 is:  Distance Metric: It measures how close data points are to each other, usually using \n",
      "\n",
      "The content of paragraphs140 is: Euclidean distance. \n",
      "\n",
      "The content of paragraphs141 is: Algorithm Steps: \n",
      "\n",
      "The content of paragraphs142 is: Step 1: Initialization \n",
      "\n",
      "The content of paragraphs143 is:  Input: Dataset with 'n' data points and the desired number of clusters 'k'. \n",
      "\n",
      "The content of paragraphs144 is:  Process: \n",
      "\n",
      "The content of paragraphs145 is:  Randomly select 'k' data points from the dataset as initial centroids. \n",
      "\n",
      "The content of paragraphs146 is: Step 2: Assignment \n",
      "\n",
      "The content of paragraphs147 is:  Input: Initial centroids. \n",
      "\n",
      "The content of paragraphs148 is:  Process: \n",
      "\n",
      "The content of paragraphs149 is:  For each data point in the dataset, calculate the Euclidean distance to each \n",
      "\n",
      "The content of paragraphs150 is: centroid. \n",
      "\n",
      "The content of paragraphs151 is:  Assign the data point to the cluster associated with the nearest centroid. \n",
      "\n",
      "The content of paragraphs152 is: 3 Step 3: Update \n",
      "\n",
      "The content of paragraphs153 is:  Input: Assigned clusters. \n",
      "\n",
      "The content of paragraphs154 is:  Process: \n",
      "\n",
      "The content of paragraphs155 is:  Recalculate the centroids of each cluster by computing the mean of all data points \n",
      "\n",
      "The content of paragraphs156 is: in that cluster. \n",
      "\n",
      "The content of paragraphs157 is: Step 4: Convergence Check \n",
      "\n",
      "The content of paragraphs158 is:  Input: Updated centroids. \n",
      "\n",
      "The content of paragraphs159 is:  Process: \n",
      "\n",
      "The content of paragraphs160 is:  Repeat the assignment and update steps iteratively until convergence. \n",
      "\n",
      "The content of paragraphs161 is:  Convergence occurs when the centroids no longer change significantly or after a \n",
      "\n",
      "The content of paragraphs162 is: fixed number of iterations. \n",
      "\n",
      "The content of paragraphs163 is: \n",
      "\n",
      "The content of paragraphs164 is: Step 5: Result \n",
      "\n",
      "The content of paragraphs165 is:  Output: Final clusters. \n",
      "\n",
      "The content of paragraphs166 is:  Process: \n",
      "\n",
      "The content of paragraphs167 is:  Once convergence is reached, the algorithm stops, and each data point is assigned \n",
      "\n",
      "The content of paragraphs168 is: to a specific cluster. \n",
      "\n",
      "The content of paragraphs169 is: Pseudo code: \n",
      "\n",
      "The content of paragraphs170 is: 1. Randomly initialize k centroids: c_1, c_2, ..., c_k \n",
      "\n",
      "The content of paragraphs171 is: 2. Repeat until convergence: \n",
      "\n",
      "The content of paragraphs172 is: a. For each data point x_i, assign it to the cluster with the closest centroid: \n",
      "\n",
      "The content of paragraphs173 is: j = argmin_k ||x_i - c_k||^2 \n",
      "\n",
      "The content of paragraphs174 is: b. Update centroids: c_k = (1/|cluster k|) * Σ x_i for all i in cluster k\n",
      "\n",
      "The content of paragraphs175 is: \n",
      "\n",
      "The content of paragraphs176 is: Program 1: Implement a program to cluster a dataset using K-means clustering. \n",
      "\n",
      "The content of paragraphs177 is: Example 1: iris flowers \n",
      "\n",
      "The content of paragraphs178 is: \n",
      "\n",
      "The content of paragraphs179 is: \n",
      "\n",
      "The content of paragraphs180 is: \n",
      "\n",
      "The content of paragraphs181 is: \n",
      "\n",
      "The content of paragraphs182 is: OUTPUT:\n",
      "\n",
      "The content of paragraphs183 is: \n",
      "\n",
      "The content of paragraphs184 is: \n",
      "\n",
      "The content of paragraphs185 is: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(document.paragraphs)):\n",
    "    print(\"The content of paragraphs\"+str(i)+\" is: \"+document.paragraphs[i].text+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eceeb6b8-8f4f-47c7-9cdb-af50cabf856a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c33fc303-8c86-473b-9ec2-97c6091a3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urllib2\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "914d993a-7af3-4990-8a3f-6104fbc1c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=urllib2.urlopen('https://en.wikipedia.org/wiki/Natural_language_processing')\n",
    "html_doc=response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6a1ca-8d63-4cca-a6b8-f503c34e0dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(html_doc,'html.parser')\n",
    "strhtml=soup.prettify()\n",
    "print(strhtml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
